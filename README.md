# bigramLanguageModel
This is a Simple Bigram Language Model created as a a hands-on exploration of language modeling concepts, such as word probabilities, text generation, and tokenization. It was interesting to feed different bodies of text into the model and witness the diversity in the sentences it generates. Through testing, we can observe how slight adjustments in training data influence the generated output.

You can run this locally by using the following command: python3 main.py -i input.txt -o generated.txt
This uses any inputted text to generate a sentence based on the word pair frequencies and copies them to a file called generated.txt.


